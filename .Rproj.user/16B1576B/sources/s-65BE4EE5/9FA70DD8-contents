---
title: "Rokt work test"
author: "Don Li (donli.datascience@gmail.com)"
email: ""
date: "18/04/2021"
output: 
  html_document: 
    fig_caption: yes
    smart: no
    code_folding: hide
knit: (
  function(inputFile, encoding) { 
    rmarkdown::render( 
      input       = inputFile, 
      encoding    = encoding, 
      output_file = "index.html")
    })
---

```{r setup, include=FALSE}
library(data.table)
knitr::opts_chunk$set(echo = TRUE)
```

# Rokt work test

## Preamble

Thank you for looking at my submission or the Rokt engineering recruiting work test. I have chosen
to do the work test using `R`, rather than `python`. This is because I was planning to do some
Bayesian analyses, and I am more familiar with the Bayesian packages in `R` (e.g., `rstan`, `rjags`) than with the `python` versions (e.g., `PyStan`, `PyJAGS`, `PyMC3`).

## Section 1. Data cleaning and exploratory analysis

```{r}
# Reading the dataset
dataset = fread("../rokt_hKllMfFFdA.csv")
```

I looked through all of the columns and the constituent data (e.g., categories for categorical
and numerical summaries for numerical data). The following are some brief notes about the
results of the data cleaning process. I omit the analysis of every variable for brevity.

#### `device`

The table below shows a frequency table of the `device` categories.
```{r}
table(dataset$device)
```

We see a small number of devices with an empty string category and two `mobile`/`Mobile` device categories. Thus, we re-code `mobile` to `Mobile`.

```{r}
dataset[ device == "mobile", device := "Mobile" ]
```

There was also a small proportion of people who had missing device categories. From a cursory
examination, those with missing devices did not have any apparent difference with the rest of
the dataset. For aggregate analyses, I will not remove them, but missing devices will be removed
in an analysis that uses `device`.

#### `gender`

The dataset contains three gender groups, `male`, `female`, and missing (empty string).

```{r}
table(dataset$gender)
```

The missing values seem well-populated and there does not appear to be anything different about this group in terms of the other variables. It seems reasonable to keep the third category.

#### `group`

```{r}
group_table = table(dataset$group)
group_proportion = group_table / sum(group_table)
group_proportion_print = round(group_proportion * 100, 2) 
```

From the data and the documentation, the allocation of users to `group` was unclear. Overall,
about `r group_proportion_print["treatment"]` % of users were in the treatment group. A
common split is 50/50 between two groups in an A/B test. It is possible that the users were
split 50/50 but as a function of another variable (e.g., `agegroup` or `gender`). But this did
not appear to be the case. Thus, we go forth assuming that the probability of a user being
allocated to the `treatment` group is around 85%.

```{r}
group_by_sessionid = dataset[ , length(unique(group)), by = "sessionid" ]
multiple_groups_per_session = group_by_sessionid[ V1 > 1, .N ]
```

In addition, I also checked the grouping by `sessionid`. I found `r multiple_groups_per_session`
sessions where the user was assigned to both groups. There did not seem to be anything unusual
about these sessions and since the number of small, I will leave them in the dataset.

#### `campaigntimestamp`

There is one observation where the time-stamp is recorded as the year 2039. Because it is only
one observation, I will remove it from the dataset. If it was more (e.g., more than 500), I would consider attempting to reassign the year using some kind of multiple imputation method.
This also means that `cohort` will have one unusual value.

I will make the change to `campaigntimestamp` and `cohort` after the data check.

#### `bidprice_usd`

At first, it seemed unusual for `bidprice_usd` to be zero, and especially so when
`bidprice_usd` was zero and the corresponding `value` was greater than zero. However, after
some research (https://support.google.com/google-ads/answer/2459326?hl=en), it seems
plausible that these were situations where there were no other bids, so an auction could
be won with a bid price of zero.

```{r}
mean_value_free_bid = dataset[ bidprice_usd == 0, mean(value, na.rm=T) ]
mean_value_nofree_bid = dataset[ bidprice_usd > 0, mean(value, na.rm=T) ]
mean_value_free_bid_print = round(mean_value_free_bid, 2)
mean_value_nofree_bid_print = round(mean_value_nofree_bid, 2)
```

As a sanity check, when the bid was free, the average value generated was `r mean_value_free_bid_print`, 
which was lower than the average when the bid was not free `r mean_value_nofree_bid_print`. 

The following histogram shows the distribution of positive bid prices. There do not seem to be any outliers.

```{r}
dataset[bidprice_usd > 0, {
    hist(bidprice_usd, main = "bidprice_usd", breaks = 25)
    NULL
} ]
```

#### `value`

The table below shows some selected quantiles of the `value` distribution.

```{r}
quantiles = c(0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1)
quantile_table = dataset[ !is.na(value), quantile(value, probs = quantiles) ]
round(quantile_table, 2)
```

We notice some extremely high `value` values. A subset of the dataset with the highest 20 `value`s are shown below:

```{r}
dataset[ order(-value) ][0:20, {
    list(agegroup, bidprice_usd, campaigntimestamp, 
         device, gender, group, value, verticalname)
    }]
```

It is notable that of the top 20, all the users are female and most of them were in the 
`treatment` group. There does not seem to be any reason *a priori* to ascribe any meaning to
all the users in this subset being female. However, it does make sense that most of the
users were assigned to the `treatment` group, as we would expect the treatment to increase the
conversion value.

So, while it is possible that the observations with `value` larger than 2000 are real data
(e.g., as opposed to a data recording error), they are not representative of the rest of
the dataset. Further, if we are interested in effects on the purchasing behaviour of usual
customers in usual situations, then we should omit these extreme values.

Thus, I exclude events where the `value` is greater than 2000.

```{r}
# A bit weird to do index not in set of values greater than 2000, but
# we have to account for NA values.
dataset = dataset[ !1:.N %in% which(value > 2000) ]
```


#### Other variables

The other variables seemed okay.

### Data check

The data check is comprised mostly of:

* Checks for the type of the variable
* If categorical, check the categories
* Also if categorical, recode to a `factor` variable for convenience
* If numeric, check for the appropriate range (e.g., greater than zero and finite)
* Recode the `campaigntimestamp` to `POSIXct` for date arithmetic
* Check that the `cohort` is generated correctly as `YYYYMM` from the time-stamp.

The implementation is done using `R`'s version of assertions. There is an "`interactive`" mode
where summaries are printed upon execution.

```{r}
data_check = function(dataset, interactive_mode=FALSE){
    ##### agegroup checks #####
    # Allow character or factor so we can run the data check multiple times
    agegroup_class = any(class(dataset$agegroup) %in% c("character", "factor"))
    agegroup_categories_reference = c("18-25", "26-30", "31-35", "36-40", "41-45", "46-55", "56-65", "65+")
    age_table = table(dataset$agegroup)
    agegroup_categories = setequal(names(age_table), agegroup_categories_reference)
    
    dataset[ , agegroup := {
        factor(agegroup, levels = names(age_table), ordered = TRUE)
    } ]
    # stopifnot() is similiar to assert in Python
    stopifnot(agegroup_class,
              agegroup_categories)
    
    if (interactive_mode) {
        print("agegroup")
        print(age_table)
    }
    
    ##### bidprice_usd checks #####
    bid_price_na = all( !is.na(dataset$bidprice_usd) )
    bid_price_positive = all( dataset$bidprice_usd >= 0 )
    bid_price_finite = all( is.finite(dataset$bidprice_usd) )
    stopifnot(bid_price_finite, 
              bid_price_na, 
              bid_price_positive)
    
    if (interactive_mode){
        print("bidprice_usd")
        print(summary(dataset$bidprice_usd))
    }
    
    ##### group check #####
    group_categories_reference = c("treatment", "control")
    group_table = table(dataset$group)
    group_split_proportion = (group_table / sum(group_table)) > 0.05
    group_categories = setequal(names(group_table), group_categories_reference)
    
    stopifnot(group_split_proportion,
              group_categories)
    
    if (interactive_mode){
        print("group split")
        print(group_split_proportion)
    }
    
    ##### campaigntimestamp check #####
    timestamp_class = any(class(dataset$campaigntimestamp) %in% c("character", "POSIXct"))
    min_date = as.POSIXct("2020-01-01")
    max_date = as.POSIXct(Sys.Date())
    
    dataset[ , campaigntimestamp := {
        as.POSIXct(campaigntimestamp, format = "%Y-%m-%d %H:%M:%S")
    } ]
    
    timestamp_in_range = all(
        dataset$campaigntimestamp >= min_date &
        dataset$campaigntimestamp <= max_date
    )
    
    stopifnot(timestamp_class,
              timestamp_in_range)
    
    if (interactive_mode){
        print("campaigntimestamp range")
        print(range(dataset$campaigntimestamp))
    }
    
    ##### cohort #####
    cohort_class = class(dataset$cohort) == "integer"
    cohort_table = table(dataset$cohort)
    
    invalid_cohort_code = dataset[ , {
        char_year = as.character(year(campaigntimestamp))
        char_month = sprintf("%02d", as.integer(month(campaigntimestamp)))
        cohort_code = sprintf("%s%s", char_year, char_month)
        which(cohort_code != cohort)
    } ]
    
    stopifnot(cohort_class,
              length(invalid_cohort_code) == 0 )
    
    if (interactive_mode){
        print("cohort")
        print(cohort_table)
    }
    
    ##### device #####
    device_class = class(dataset$device) %in% c("character", "factor")
    
    dataset[device == "mobile", device := "Mobile" ]
    dataset = dataset[device != ""]
    
    device_reference = c("Desktop", "Mobile", "Other", "Tablet")
    
    device_table = table(dataset$device)
    device_categories = setequal(names(device_table), device_reference)
    
    if (interactive_mode){
        print("device table")
        print(device_table)
    }
    
    stopifnot(device_class,
              device_categories)
    
    dataset[ , device := factor(device, levels = device_reference) ]
    
    ##### userhash #####
    userhash_class = class(dataset$userhash) == "character"
    
    stopifnot(userhash_class)
    
    ##### gender #####
    gender_class = class(dataset$gender) %in% c("character", "factor")
    
    gender_table = table(dataset$gender)
    gender_reference = c("", "f", "m")
    
    
    gender_categories = setequal(names(gender_table), gender_reference)
    
    stopifnot(gender_class,
              gender_categories)
    
    dataset[ , gender := factor(gender, levels = gender_reference) ]
    if (interactive_mode){
        print("gender table")
        print(gender_table)
    }
    
    ##### sessionid #####
    session_id_class = class(dataset$sessionid) == "character"
    unique_users_per_session = dataset[ , {
        length(unique(userhash))
    }, by = "sessionid" ]
    unique_users_in_session = all(unique_users_per_session$V1 == 1)
    
    stopifnot(session_id_class, 
              unique_users_in_session)
    
    ##### verticalname #####
    verticalname_class = class(dataset$verticalname) %in% c("character", "factor")
    verticalname_reference = c("Finance", "Food and Beverage", "Loyalty and Samples", 
        "Media and Entertainment", "Retail", "Sports and Fitness", "Ticketing",
        "Travel")
    verticalname_table = table(dataset$verticalname)
    
    verticalname_categories = setequal(names(verticalname_table), verticalname_reference)
    
    stopifnot(verticalname_class,
              verticalname_categories)
    
    dataset[ , verticalname := factor(verticalname, levels = verticalname_reference) ]
    
    if (interactive_mode){
        print("verticalname table")
        print(verticalname_table)
    }
    
    ##### value #####
    value_class = class(dataset$value) == "numeric"
    
    value_non_na_finite = all( is.finite(dataset[!is.na(value)]$value) )
    value_non_na_positive = all( dataset[!is.na(value)]$value > 0 )
    
    stopifnot(value_class, 
              value_non_na_finite, 
              value_non_na_positive)
    
    if (interactive_mode){
        print("value summary")
        print(summary(dataset$value))
    }
}
```

The following code block runs the data check and by design, returns an error about the invalid time-stamp.

```{r}
# Run inside a try(), so the document does not crash
try({
    data_check(dataset)
})
```

And here, we omit the observation with the incorrect date and check the data again.

```{r}
dataset = dataset[campaigntimestamp <= as.POSIXct(Sys.Date())]
data_check(dataset)
```


## Section 2. Conversion rates

In this section, we want to compute conversion rate. In the next section, we want to determine if Rokt had a positive or negative impact. Thus, in the present section, I will focus on computation and numerical differences. In the next section, I will consider the variance of the conversion rate.


```{r}
compute_conversion_rate = function(value, userhash){
    converted_users = !is.na(value)
    converted_hashes = unique(userhash[converted_users])
    n_unique_conversions = length(converted_hashes)
    
    unique_users = unique(userhash)
    n_unique_users = length(unique_users)
    
    n_unique_conversions/n_unique_users
}
overall_conversion_rate = dataset[ , compute_conversion_rate(value, userhash) ]
overall_conversion_rate_print = round( overall_conversion_rate * 100, 2 )
conversion_rate_by_cohort = dataset[ , {
    conversion_rate = compute_conversion_rate(value, userhash)
    conversion_rate_print = round(conversion_rate * 100, 2)
    list(conversion_rate = conversion_rate,
        "conversion rate %" = conversion_rate_print)
    }, by = c("cohort") ]
```

The overall conversion rate was `r overall_conversion_rate_print` %, the conversion rates for each cohort were:

```{r}
conversion_rate_by_cohort[ , list(cohort, `conversion rate %`) ]
```

It seems unusual to look at conversion rate by `cohort` without also looking at conversion rate by treatment group,
since, we want to know what the effect of the A/B manipulation is on the conversion value. So, the graph below
shoes the conversion rate by cohort and group.

```{r echo=FALSE}
conversion_rate_by_cohort_group = dataset[ , {
    conversion_rate = compute_conversion_rate(value, userhash)
    time_year = year(campaigntimestamp[1])
    time_month = month(campaigntimestamp[1])
    date_ = sprintf("%s-%02d", time_year, time_month)
    list( conversion_rate = conversion_rate, date_ = date_ )
    }, by = c("cohort", "group") ]

conversion_rate_by_cohort_group[ , {
    treatment_conversion = conversion_rate[group == "treatment"] * 100
    control_conversion = conversion_rate[group == "control"] * 100
    N = length(treatment_conversion)
    date_names = as.character(date_[group == "treatment"])
    plot(1:N,
        ylim = range(conversion_rate * 100),
        xaxt = "n", xlab = "Cohort (YYYY-MM)",
        ylab = "Conversion rate %", type = "n", col = "red",
        main = "Conversion rate per cohort and treatment")
    axis(side = 1, at = 1:N, labels = date_names)
    lines(1:N, treatment_conversion, col = "red")
    lines(1:N, control_conversion, col = "blue")
    lines(1:N, conversion_rate_by_cohort$conversion_rate*100, col = "green")
    legend(x = "bottomleft",
        legend = c("Treatment", "Control", "Aggregate"),
        col = c("red", "blue", "green"), lty = 1, bty = "n")
    NULL
} ]
```

Figure 1. Conversion rate per cohort and treatment group.

We see that the conversion rate has been decreasing from 2020-02 to 2020-06. If we suppose that this is real data,
then this decrease could be explained by COVID lockdowns, if the products that these conversions are linked to are
those that involve people going outside.


## Section 3. Does Rokt provide a positive or negative impact?

Here, we want to know if the advertisements served by Rokt (henceforth 'treatment') has an effect on the conversion rate. 
Because we have seen previously that the time period (`cohort`) has an effect on the overall conversion rate, 
we should account for it in our analysis.

For a model-based analysis, I will assume the underlying decision process:

* A user is served an advertisement
* They can choose whether or not to purchase the good/service that is being advertised (binary choice; conversion)

We assume:

* That users in different time periods (`cohort`) can have different probabilities of conversion.
* Serving an advertisement may have some effect on the probability of conversion.

For simplicity, we further assume:

* Within each time period, users are identical in their decision process, but with some non-systematic variability between users.
* The effect of treatment group does not depend on time period (i.e., we are interested in the main effect of the treatment).

We represent these processes and assumptions as a binomial Generalised Linear Model. That is:

$x_{t, a} \sim \mathrm{Binomial}(p_{t, a}, n_{t, a})$

$p_{t, a} = g^{-1}(\beta_0 + \beta_1 t + \beta_{2} \mathbb{I}_{a=1})$

where $x_{t, a}$ is the number of unique conversions for the time period ($t$) and whether they were in the treatment group 
($a = 1$). $n_{t, a}$ is the corresponding known number of unique users (i.e., opportunities for unique conversions). 
 $g^{-1}$ is the inverse logit.

In addition, I will extend the model to be a Bayesian model. I use fairly diffuse Normal priors for the intercept $\beta_0$
and the effect of treatment ($\beta_1$). I use a narrower Normal prior for the treatment ($\beta_2$) effect.

In principle, there is no need to assume the number of conversion opportunities is fixed. We could model the rate of incoming
users using Poisson distributions. However, this is beyond the scope of the current assessment.

```{r}
run_model = FALSE
if (run_model){
    conversion_rate_dataset = dataset[ ,{
        unique_users = unique(userhash)
        n_unique_users = length(unique_users)
        converted_users = !is.na(value)
        converted_hashes = unique(userhash[converted_users])
        n_unique_conversions = length(converted_hashes)
    
        list(
            N_conversions = n_unique_conversions,
            N_total = n_unique_users
        )
    }, by = c("cohort", "group") ]
    conversion_rate_dataset[ , cohort_numeric := as.numeric(factor(cohort)) ]
    conversion_rate_dataset[ , group_numeric := as.numeric(factor(group)) - 1 ]
    
    jags_data = as.list(conversion_rate_dataset)
    jags_data$N_cohorts_x_treatment = nrow(conversion_rate_dataset)
    
    library(rjags)
    model_string = "model{
        # in JAGS, normal distribution is parameterised with the precision
        beta1 ~ dnorm(0, 1/5)
        treatment_effect ~ dnorm(0, 1)
        beta0 ~ dnorm(0, 1/5)
        
        for (i in 1:N_cohorts_x_treatment){
            logit(p[i]) = beta0 +
                          beta1 * cohort_numeric[i] +
                          treatment_effect * group_numeric[i]
            N_conversions[i] ~ dbin(p[i], N_total[i])
            predict_N_conversions[i] ~ dbin(p[i], N_total[i])
        }
    }"
    
    conversion_model = jags.model(textConnection(model_string), jags_data, n.chains = 1)
    variable_names = c("beta1", "beta0", "treatment_effect", "predict_N_conversions")
    conversion_posterior = coda.samples(conversion_model, variable.names = variable_names, n.iter = 1e5, thin = 25 )
    
    conversion_posterior_dt = data.table(conversion_posterior[[1]])
    conversion_posterior_dt[ , c("beta0_odds", "treatment_odds", "beta1_odds") := {
        list(exp(beta0), exp(treatment_effect), exp(beta1))
    } ]
    
    posterior_names = names(conversion_posterior_dt)
    predict_names = posterior_names[ grepl("predict_N", posterior_names) ]
    
    posterior_predictive_list = lapply(conversion_posterior_dt[ , mget(predict_names) ], list)

    conversion_rate_dataset[ , posterior_predictive := as.list(conversion_posterior_dt[ , mget(predict_names) ]) ]

    save(conversion_posterior_dt, conversion_rate_dataset, file = "posterior.RData")
} else{
    load("posterior.RData")
}

```

The figure below shows the posterior distributions for the cohort and treatment effects on the logit space. Because these posteriors are far from zero, we have very strong evidence that:

* The conversion rates were decreasing over time (over cohorts).
* The conversion rates were higher for the treatment group.

```{r fig.width=9}
par(mfrow = c(1,2))
hist(conversion_posterior_dt$beta1, prob = T, main = "Cohort effect (lower is worse)",
    xlim = c(-0.20, 0), breaks = 50)
abline(v = 0, col = "red")
hist(conversion_posterior_dt$treatment_effect, prob = T, main = "Treatment effect (higher is better)",
    xlim = c(0, 0.3))
abline(v = 0, col = "red")
```

Figure 2. Posteriors for the cohort (time) effect and treatment effect. These coefficients are on the logit space. 
The vertical lines mark zero on the x axes.

However, because the coefficients are relatively unintuitive to interpret on the logit space, I will also show the
posterior predicted number of conversions for each cohort and treatment group. Because these are in terms of the
quantity of interest (conversion rate), it should be easier to understand the implications of cohort and
treatment.

```{r}
posterior_predicted_conversion = conversion_rate_dataset[ , {
    list(predicted_conversion_rate = posterior_predictive[[1]] / N_total)
}, by = c("cohort", "group") ]
mean_table = posterior_predicted_conversion[ , mean(predicted_conversion_rate), by = c("cohort", "group") ][ , {
    diff = V1[group == "treatment"] - V1[group == "control"]
    list("Treatment - Control mean" = diff,
        "Incrementality" = diff/V1[group == "treatment"])
}, by = "cohort" ]
```

From Figure 3, we see that across all cohorts, the treatment yielded an increase in conversion rate compared to the control group. Because the
posteriors are well-separated for each cohort, we have high confidence in the effect of the treatment. Table 1 shows the average difference between
the treatment groups for each cohort. There may be a decreasing trend in the effect of the treatment, suggesting that the effect of the treatment could
depend on the cohort, but that is secondary to the treatment increasing the conversion rate.

Further, Table 1 also shoes the incrementality. On average, we see about 17% incrementality across the cohorts.

```{r fig.height=7, fig.width=9}
par( mfrow = c(3,2) )
for (cohort_ in unique(posterior_predicted_conversion$cohort)){
    temp_data = posterior_predicted_conversion[cohort == cohort_]
    header = sprintf("Cohort: %s", cohort_)
    conversion_treatment = 
    density_treatment = density(temp_data[group == "treatment"]$predicted_conversion_rate)
    plot( density_treatment,
        xlim = c(0.01, 0.04),
        xlab = c("Predicted conversion rate"),
        main = header)
    lines( density(temp_data[group == "control"]$predicted_conversion_rate), col = "red" )
    legend(x = "topright", col = c("black", "red"), lty = 1,
        legend = c("Treatment", "Control"), bty = "n")
}
```

Figure 3. Posterior predicted conversion rates per group and cohort.

```{r}
mean_table
```

Therefore, we have quite strong evidence that, when accounting for the decrease in conversion rate across cohorts,
that Rokt had a positive impact and increased conversions.


# Section 4. Other metrics

In this section, I interpret "other metrics" as metrics that are not conversion rate.

```{r}
bidprice_value_dataset = dataset[ !is.na(value) ]
bidprice_value_dataset[ , agegroup := factor(agegroup, ordered = FALSE) ]
```

For this section, I set up a hypothetical business problem:

* Given that we have chosen to serve an advertisement and that it has generated value, how do we maximise the value generated?

In this analysis, we will focus on the effect of `bidprice`, `agegroup`, `device`, `cohort`, `gender`, and `verticalname` on
the value of conversions. Thus, we can see which demographics or bidding policies can lead to higher conversion values.

This dataset for this analysis contains events where the value of the conversion/purchase was greater than zero. Thus, this
dataset contains about 16,000 observations. This is too many for `rjags` to handle within a reasonable time frame. There are
other tools that could allow us to do a Bayesian analysis on larger datasets (e.g., `torch` and `pyro`). But to keep the analysis
simple, we will use a (non-Bayesian) Gamma Generalised Linear Model. I use the log link here due to personal preference.

As per Section 1, because we have `device` in our analysis, I will remove the observations with missing device values.

```{r}
bidprice_value_dataset = bidprice_value_dataset[ device != "" ]
```

```{r}
model_value = glm(value ~ bidprice_usd + agegroup + device + cohort + gender + verticalname,
    data = bidprice_value_dataset, family = Gamma(link = "log"))
anova_results = anova(model_value, test = "LRT")
```

An ANOVA on the model terms shows that `cohort` did not have a significant effect on the conversion value. The boxplot below (Figure 4) shows that the conversion values were similar across cohorts.

```{r}
boxplot(value ~ cohort, bidprice_value_dataset) 
```

Figure 4. Conversion value by cohort.

We run the analysis again dropping the `cohort` variable. This is mostly to simplify the subsequent analysis.

```{r}
model_value = glm(value ~ bidprice_usd + agegroup + device + gender + verticalname,
    data = bidprice_value_dataset, family = Gamma(link = "log"))
anova_results = anova(model_value, test = "LRT")

bidprice_effect = round(exp(model_value$coefficients["bidprice_usd"]), 3)
```

From the analysis, we found that for every dollar increase in the bid price, the value of the conversions increased by `r bidprice_effect` times. This is while adjusting for the effects of the other variables. Figure 5 below shows the relationship
between value and bid price. From the figure, there appears to be two groups of events, one where the bid price is low and the
corresponding conversion values range from 0 to 400; and another group where the value is increasing with bid price.
Without further analysis, I am unsure of what the cause of this pattern is. For example, it could be for some subset of users,
the bid price has no effect on the conversion value. This would be an opportunity for future research.

```{r}
bidprice_value_dataset[ , {
    plot(bidprice_usd, value)
    NULL
    } ]
desktop_other_diff = 1 - round(exp(model_value$coefficients["deviceOther"]), 3)
```

We found that the type of device had an effect on the conversion values. People on "Other" devices tended to have lower conversion values than those on desktop/mobile/tablet devices. In contrast, people on Desktop devices had the highest conversion values.
Indeed, users on desktops had `r desktop_other_diff` times higher conversion values than those on "Other" devices.
This makes sense given that people probably tend to do more online shopping for big-purchase items on their desktops than
their mobile devices. A series of boxplots is shown in Figure 6.

```{r}
boxplot(value ~ device, data = bidprice_value_dataset)
```

Figure 6. Conversion value by user device.

```{r}
m_missing_diff = t.test( bidprice_value_dataset[gender == "m"]$value, bidprice_value_dataset[gender == ""]$value )
f_missing_diff = t.test( bidprice_value_dataset[gender == "m"]$value, bidprice_value_dataset[gender == ""]$value )
m_effect = 1 - round(exp(model_value$coefficients["genderm"]), 3)
f_effect = 1 - round(exp(model_value$coefficients["genderf"]), 3)
```

We also found that males and females had significantly higher conversion values than those who had missing genders. It is unclear
why this would occur. A boxplot is shown in Figure 7. The difference between male/female and missing gender was about 0.5%.
Because this difference is relatively small and unexplainable a priori, we will focus on other covariates.

```{r}
boxplot(value ~ gender, data = bidprice_value_dataset)
```

Figure 7. Conversion value by gender.

We found that there were differences in conversion rates between industry/domain (`verticalname`). A boxplot is shown in Figure 8.
The conversion values for advertisements in the Finance industry were particularly high. However, the sample size is very small
(4). For the more populated groups, advertisements in the retail industry tended to be slightly higher than the other industries.

```{r}
par(mar=c(11, 4.1, 4.1, 2.1))
bidprice_value_dataset[ , verticalname_factor := factor(verticalname) ]
boxplot( value ~ verticalname_factor, data = bidprice_value_dataset,
    xlab = "", las = 2)
```

Figure 8. Conversion value by industry/domain.

## Conclusions

To optimise the value of conversions, I suggest:

* Be less conservative with bid pricing
* Prioritise bidding for advertisements for desktop users over mobile/other users
* Be willing to bid more or more frequently for advertisements in the retail domain

Areas of additional research would include:

* Getting additional data for advertisements in the Finance industry
* Investigating the reason why people with missing genders tended to have lower conversion values
* The cause of the two groups in the bid price - value relationship

If we still see a robust differences in conversion value from the Finance industry advertisements after getting a larger
dataset, then this would correspond to the identification of a more lucrative market.

With additional data, we can:

* With more information about operational costs, we can estimate the amount of profit that changing the bidding
policies would generate.



